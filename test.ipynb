{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试用文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 得到标签字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='latin1')\n",
    "    return dict\n",
    "\n",
    "dict = unpickle('dataset/cifar-100-python/meta')\n",
    "# print(dict)\n",
    "\n",
    "label_list = dict['fine_label_names']\n",
    "# print(len(label_list))\n",
    "# print(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #取第一个图片显示一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dataset\n",
    "\n",
    "images = None\n",
    "labels = None\n",
    "\n",
    "for batch in dataset.train_loader:\n",
    "    images, labels = batch\n",
    "    break\n",
    "\n",
    "label = labels[0]\n",
    "image = images[0]\n",
    "\n",
    "print(\"标签:\" + str(label_list[label]))\n",
    "\n",
    "#反归一化\n",
    "mean = (0.5071, 0.4867, 0.4408)\n",
    "std = (0.2675, 0.2565, 0.2761)\n",
    "\n",
    "dmean = [-mean/std for mean, std in zip(mean, std)]\n",
    "dstd = [1/std for std in std]\n",
    "\n",
    "image = transforms.Normalize(dmean, dstd)(image)\n",
    "image = transforms.ToPILImage(mode=\"RGB\")(image)\n",
    "\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 测试tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    for j in tqdm(range(5)):\n",
    "        print(i,\" \",j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 测试numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "matrix = [[1,2,3],[4,5,6]]\n",
    "print(matrix[1][2])\n",
    "print(matrix)\n",
    "tensor = numpy.array(matrix)\n",
    "print(tensor)\n",
    "print(tensor[1][2])\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 形状测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "\n",
    "mean = (0.5071, 0.4867, 0.4408)\n",
    "std = (0.2675, 0.2565, 0.2761)\n",
    "\n",
    "transform=transforms.Compose([        \n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=mean,std=std)\n",
    "                ])\n",
    "\n",
    "train_dataset=datasets.CIFAR100(\n",
    "                    root='dataset',  \n",
    "                    train=True,     \n",
    "                    download=True,  \n",
    "                    transform=transform\n",
    "                )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                                        batch_size=16,\n",
    "                                                        shuffle=True)\n",
    "\n",
    "for data in train_loader:\n",
    "    images, labels = data\n",
    "    print(images.shape)\n",
    "    print(images.dtype)\n",
    "    print(labels.shape)\n",
    "    print(labels[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 测试deepcopy会不会将权重一并复制\n",
    "答案：会"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet50(weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "new = copy.deepcopy(model)\n",
    "new_dict = new.state_dict()\n",
    "\n",
    "flag=True\n",
    "for name, param in new_dict.items():\n",
    "    if (state_dict[name] != param).any():\n",
    "        flag = False\n",
    "    print(param.dtype)\n",
    "\n",
    "print(1 if flag else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 测试数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 0.0\n",
    "c = 2\n",
    "d = a/c\n",
    "print(type(a), type(b), type(c), type(d) )\n",
    "\n",
    "import torch\n",
    "a = torch.tensor([1,2,3])\n",
    "b = torch.zeros_like(a, dtype=torch.float32)\n",
    "print(b.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "model = torchvision.models.resnet50(weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2 )\n",
    "new = torchvision.models.resnet50()\n",
    "\n",
    "diff = {}\n",
    "for name, data in model.state_dict().items():\n",
    "    diff[name] = (data - new.state_dict()[name])\n",
    "\n",
    "for name, data in diff.items():\n",
    "    print(data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "list = range(10)\n",
    "a,b = torch.utils.data.random_split(list, [3,5])\n",
    "for i in a:\n",
    "    print(i)\n",
    "print()\n",
    "for i in b:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet50(weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "new = torchvision.models.resnet50(weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "diff = {}\n",
    "for name, data in model.state_dict().items():\n",
    "    diff[name] = (data - new.state_dict()[name])\n",
    "for name, data in diff.items():\n",
    "    print(data.dtype)\n",
    "    break\n",
    "\n",
    "weight_accumulator = {}\n",
    "for name, data in model.state_dict().items():\n",
    "    weight_accumulator[name] = torch.zeros_like(data, dtype=torch.float32)\n",
    "for name, data in weight_accumulator.items():\n",
    "    print(data.dtype)\n",
    "    break\n",
    "\n",
    "for name, _ in model.state_dict().items():\n",
    "    weight_accumulator[name].add_(diff[name])\n",
    "for name, data in weight_accumulator.items():\n",
    "    print(data.dtype)\n",
    "    break\n",
    "\n",
    "for name, param in model.state_dict().items():\n",
    "    # 得到每一层的更新\n",
    "    update_per_layer = weight_accumulator[name] * 0.1\n",
    "    print('---')\n",
    "    print(update_per_layer.dtype)\n",
    "    #   加上每一层更新\n",
    "    # .add_()方法是不产生新张量\n",
    "    param.add_(update_per_layer)\n",
    "for name, data in model.state_dict().items():\n",
    "    print(data.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 测试subsetrandomsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "dataset = TensorDataset(torch.tensor(list(range(20))))  # 构造一个数据集（0到19）\n",
    "\n",
    "idx = list(range(len(dataset)))  # 创建索引，SubsetRandomSampler会自动乱序\n",
    "\n",
    "train_sampler = SubsetRandomSampler(idx[10:])  # 随机取80%的数据做训练集\n",
    "test_sampler = SubsetRandomSampler(idx[:10])  # 随机取20%的数据做测试集\n",
    "\n",
    "train_loader = DataLoader(dataset, sampler=train_sampler)\n",
    "test_loader = DataLoader(dataset, sampler=test_sampler)\n",
    "\n",
    "print('data for training:')\n",
    "for i in train_loader:\n",
    "    print(i)\n",
    "print('data for testing:')\n",
    "for i in test_loader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: dataset\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomCrop(size=(32, 32), padding=4)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])\n",
      "           )\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
      "c58f30108f718f92721af3b95e74349a\n"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "import util\n",
    "\n",
    "util.dir_process()\n",
    "\n",
    "train_set, val_set = dataset.get_dataset(\"cifar-10\")\n",
    "\n",
    "print(train_set)\n",
    "print(train_set.classes)\n",
    "print(train_set.class_to_idx)\n",
    "print(train_set.tgz_md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(train_set.data.shape)\n",
    "print(type(train_set[0][0]))\n",
    "print(type(train_set[0][1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
